{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob #gets list of files from directory\n",
    "import os\n",
    "import re\n",
    "\n",
    "train = sorted(glob('nyt_archive_data/train/**/*.txt', recursive=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def words(txt): return re.findall(\"[a-z0-9']+\",txt.lower())\n",
    "\n",
    "word_count = {}\n",
    "\n",
    "for f in train:\n",
    "    txt = re.sub('\\s+', ' ', open(f, 'r', encoding='utf-8').read().lower())\n",
    "    author = os.path.normpath(f).split(os.sep)[-2]\n",
    "    unique_words = set(words(txt))\n",
    "    if author in word_count:\n",
    "        word_count[author].update(unique_words)\n",
    "    else:\n",
    "        word_count[author] = Counter(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31895"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_vocab = Counter()\n",
    "for author in word_count: total_vocab += word_count[author]\n",
    "len(total_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pet_df= df = pd.read_csv('PETS-284-variations.csv', encoding = \"utf-8\")\n",
    "euph_df= df = pd.read_csv('Euphemism_Corpus.csv', encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>euphemism</th>\n",
       "      <th>type</th>\n",
       "      <th>real_meaning</th>\n",
       "      <th>category</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a certain age</td>\n",
       "      <td>a certain age</td>\n",
       "      <td>old</td>\n",
       "      <td>physical/mental attributes</td>\n",
       "      <td>Kapron-King, A.,  OED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>able-bodied</td>\n",
       "      <td>able-bodied</td>\n",
       "      <td>non disable</td>\n",
       "      <td>physical/mental attributes</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accident</td>\n",
       "      <td>accident</td>\n",
       "      <td>peeing your pants</td>\n",
       "      <td>bodily functions</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accident</td>\n",
       "      <td>accident</td>\n",
       "      <td>tragic event</td>\n",
       "      <td>misc.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>addict</td>\n",
       "      <td>addict</td>\n",
       "      <td>drug user</td>\n",
       "      <td>substances</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>well-fed</td>\n",
       "      <td>well-fed</td>\n",
       "      <td>fat</td>\n",
       "      <td>physical/mental attributes</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>went to a better place</td>\n",
       "      <td>went to a better place</td>\n",
       "      <td>died</td>\n",
       "      <td>death</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>went to be with the lord</td>\n",
       "      <td>went to be with the lord</td>\n",
       "      <td>died</td>\n",
       "      <td>death</td>\n",
       "      <td>Heerema, Esther</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>went to heaven</td>\n",
       "      <td>go to heaven</td>\n",
       "      <td>died</td>\n",
       "      <td>death</td>\n",
       "      <td>Heerema, Esther</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>with child</td>\n",
       "      <td>with child</td>\n",
       "      <td>pregnant</td>\n",
       "      <td>physical/mental attributes</td>\n",
       "      <td>Gormandy White, Mary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    euphemism                      type       real_meaning  \\\n",
       "0               a certain age             a certain age                old   \n",
       "1                 able-bodied               able-bodied        non disable   \n",
       "2                    accident                  accident  peeing your pants   \n",
       "3                    accident                  accident       tragic event   \n",
       "4                      addict                    addict          drug user   \n",
       "..                        ...                       ...                ...   \n",
       "279                  well-fed                  well-fed                fat   \n",
       "280    went to a better place    went to a better place               died   \n",
       "281  went to be with the lord  went to be with the lord               died   \n",
       "282            went to heaven              go to heaven               died   \n",
       "283                with child                with child           pregnant   \n",
       "\n",
       "                       category                 source  \n",
       "0    physical/mental attributes  Kapron-King, A.,  OED  \n",
       "1    physical/mental attributes                      -  \n",
       "2              bodily functions                      -  \n",
       "3                         misc.                      -  \n",
       "4                    substances                      -  \n",
       "..                          ...                    ...  \n",
       "279  physical/mental attributes                      -  \n",
       "280                       death                      -  \n",
       "281                       death        Heerema, Esther  \n",
       "282                       death        Heerema, Esther  \n",
       "283  physical/mental attributes   Gormandy White, Mary  \n",
       "\n",
       "[284 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>edited_text</th>\n",
       "      <th>is_euph</th>\n",
       "      <th>category</th>\n",
       "      <th>type</th>\n",
       "      <th>euph_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tinkle</td>\n",
       "      <td>We're just getting back what was TAKEN from us...</td>\n",
       "      <td>1</td>\n",
       "      <td>bodily functions</td>\n",
       "      <td>tinkle</td>\n",
       "      <td>always_euph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tinkle</td>\n",
       "      <td>I think AB390 will pass next year now that the...</td>\n",
       "      <td>1</td>\n",
       "      <td>bodily functions</td>\n",
       "      <td>tinkle</td>\n",
       "      <td>always_euph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>undocumented immigrants</td>\n",
       "      <td>Singled Out Think Like a Man, the new movie ba...</td>\n",
       "      <td>1</td>\n",
       "      <td>politics</td>\n",
       "      <td>undocumented immigrant</td>\n",
       "      <td>always_euph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>undocumented immigrants</td>\n",
       "      <td>Not to be outdone, Sen. Rand Paul (R-Ky. ), so...</td>\n",
       "      <td>1</td>\n",
       "      <td>politics</td>\n",
       "      <td>undocumented immigrant</td>\n",
       "      <td>always_euph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>undocumented immigrants</td>\n",
       "      <td>The law has also galvanized the growing immigr...</td>\n",
       "      <td>1</td>\n",
       "      <td>politics</td>\n",
       "      <td>undocumented immigrant</td>\n",
       "      <td>always_euph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>sleep with</td>\n",
       "      <td>There were other photos she wanted me to see: ...</td>\n",
       "      <td>0</td>\n",
       "      <td>sexual activity</td>\n",
       "      <td>sleep with</td>\n",
       "      <td>sometimes_euph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961</th>\n",
       "      <td>sleep with</td>\n",
       "      <td>I am relieved to see two pup tents marked STAF...</td>\n",
       "      <td>0</td>\n",
       "      <td>sexual activity</td>\n",
       "      <td>sleep with</td>\n",
       "      <td>sometimes_euph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962</th>\n",
       "      <td>sleep around</td>\n",
       "      <td>Nothing serious, just long nights of me hackin...</td>\n",
       "      <td>0</td>\n",
       "      <td>sexual activity</td>\n",
       "      <td>sleep around</td>\n",
       "      <td>sometimes_euph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963</th>\n",
       "      <td>with child</td>\n",
       "      <td>sounds more like Jonestown. They cant leave @ ...</td>\n",
       "      <td>0</td>\n",
       "      <td>physical/mental attributes</td>\n",
       "      <td>with child</td>\n",
       "      <td>sometimes_euph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>with child</td>\n",
       "      <td>Nickname of a girl named Diana. 41. What you d...</td>\n",
       "      <td>0</td>\n",
       "      <td>physical/mental attributes</td>\n",
       "      <td>with child</td>\n",
       "      <td>sometimes_euph</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1965 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      keyword  \\\n",
       "0                      tinkle   \n",
       "1                      tinkle   \n",
       "2     undocumented immigrants   \n",
       "3     undocumented immigrants   \n",
       "4     undocumented immigrants   \n",
       "...                       ...   \n",
       "1960               sleep with   \n",
       "1961               sleep with   \n",
       "1962             sleep around   \n",
       "1963               with child   \n",
       "1964               with child   \n",
       "\n",
       "                                            edited_text  is_euph  \\\n",
       "0     We're just getting back what was TAKEN from us...        1   \n",
       "1     I think AB390 will pass next year now that the...        1   \n",
       "2     Singled Out Think Like a Man, the new movie ba...        1   \n",
       "3     Not to be outdone, Sen. Rand Paul (R-Ky. ), so...        1   \n",
       "4     The law has also galvanized the growing immigr...        1   \n",
       "...                                                 ...      ...   \n",
       "1960  There were other photos she wanted me to see: ...        0   \n",
       "1961  I am relieved to see two pup tents marked STAF...        0   \n",
       "1962  Nothing serious, just long nights of me hackin...        0   \n",
       "1963  sounds more like Jonestown. They cant leave @ ...        0   \n",
       "1964  Nickname of a girl named Diana. 41. What you d...        0   \n",
       "\n",
       "                        category                    type     euph_status  \n",
       "0               bodily functions                  tinkle     always_euph  \n",
       "1               bodily functions                  tinkle     always_euph  \n",
       "2                       politics  undocumented immigrant     always_euph  \n",
       "3                       politics  undocumented immigrant     always_euph  \n",
       "4                       politics  undocumented immigrant     always_euph  \n",
       "...                          ...                     ...             ...  \n",
       "1960             sexual activity              sleep with  sometimes_euph  \n",
       "1961             sexual activity              sleep with  sometimes_euph  \n",
       "1962             sexual activity            sleep around  sometimes_euph  \n",
       "1963  physical/mental attributes              with child  sometimes_euph  \n",
       "1964  physical/mental attributes              with child  sometimes_euph  \n",
       "\n",
       "[1965 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euph_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for f in train:\n",
    "    # Read the file and preprocess text\n",
    "    with open(f, 'r', encoding='utf-8') as file:\n",
    "        txt = re.sub('\\s+', ' ', file.read().lower())\n",
    "    # Extract author name from file path\n",
    "    author = os.path.normpath(f).split(os.sep)[-2]\n",
    "    # Extract title from file path\n",
    "    title = os.path.splitext(os.path.basename(f))[0]\n",
    "    # Append author, title, and text to the list\n",
    "    data.append({'author': author, 'title': title, 'text': txt})\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "train_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "euphemisms = pet_df['euphemism'].unique().tolist()\n",
    "\n",
    "def find_euphemism_sentences(text, author, title):\n",
    "    sentences = re.split(r'[.!?]+', text)  # Split text into sentences\n",
    "    matches = []\n",
    "    for sentence in sentences:\n",
    "        for euphemism in euphemisms:\n",
    "            if re.search(r'\\b' + re.escape(euphemism) + r'\\b', sentence, flags=re.IGNORECASE):\n",
    "                matches.append({\n",
    "                    'sentence': sentence.strip(),\n",
    "                    'author': author,\n",
    "                    'title': title,\n",
    "                    'pet': euphemism\n",
    "                })\n",
    "                break  # Break after the first euphemism match\n",
    "    return matches\n",
    "\n",
    "# Apply the function to each row in train_df\n",
    "results = []\n",
    "for index, row in train_df.iterrows():\n",
    "    matches = find_euphemism_sentences(row['text'], row['author'], row['title'])\n",
    "    results.extend(matches)\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>pet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in the late 1960's, the army used to solicit f...</td>\n",
       "      <td>ac</td>\n",
       "      <td>the-russians-coming-in-a-nonexistent-tank</td>\n",
       "      <td>late</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the t-64 and t-72 tanks, revealed to western e...</td>\n",
       "      <td>ac</td>\n",
       "      <td>the-russians-coming-in-a-nonexistent-tank</td>\n",
       "      <td>late</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>on the other hand, it did look very much like ...</td>\n",
       "      <td>ac</td>\n",
       "      <td>the-russians-coming-in-a-nonexistent-tank</td>\n",
       "      <td>troubled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>he admitted that united states intelligence ha...</td>\n",
       "      <td>ac</td>\n",
       "      <td>the-russians-coming-in-a-nonexistent-tank</td>\n",
       "      <td>did it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>* since january, thousands of east germans hav...</td>\n",
       "      <td>ah</td>\n",
       "      <td>east-gemrman-dissent</td>\n",
       "      <td>outspoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>, after a more experienced guide has guided th...</td>\n",
       "      <td>ws</td>\n",
       "      <td>essay-the-nsc-after-clark</td>\n",
       "      <td>experienced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>richard burt has his hands full getting conser...</td>\n",
       "      <td>ws</td>\n",
       "      <td>essay-the-nsc-after-clark</td>\n",
       "      <td>outspoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>workers who priced themselves and their indust...</td>\n",
       "      <td>ws</td>\n",
       "      <td>essay-the-recession-speaks</td>\n",
       "      <td>laid off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>then let him go to jerusalem, without precondi...</td>\n",
       "      <td>ws</td>\n",
       "      <td>essay-the-ultimate-settlement</td>\n",
       "      <td>let him go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>maybe it was a sense of betrayal that we exper...</td>\n",
       "      <td>wsc</td>\n",
       "      <td>presidential-paradoxes</td>\n",
       "      <td>experienced</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence author  \\\n",
       "0    in the late 1960's, the army used to solicit f...     ac   \n",
       "1    the t-64 and t-72 tanks, revealed to western e...     ac   \n",
       "2    on the other hand, it did look very much like ...     ac   \n",
       "3    he admitted that united states intelligence ha...     ac   \n",
       "4    * since january, thousands of east germans hav...     ah   \n",
       "..                                                 ...    ...   \n",
       "315  , after a more experienced guide has guided th...     ws   \n",
       "316  richard burt has his hands full getting conser...     ws   \n",
       "317  workers who priced themselves and their indust...     ws   \n",
       "318  then let him go to jerusalem, without precondi...     ws   \n",
       "319  maybe it was a sense of betrayal that we exper...    wsc   \n",
       "\n",
       "                                         title          pet  \n",
       "0    the-russians-coming-in-a-nonexistent-tank         late  \n",
       "1    the-russians-coming-in-a-nonexistent-tank         late  \n",
       "2    the-russians-coming-in-a-nonexistent-tank     troubled  \n",
       "3    the-russians-coming-in-a-nonexistent-tank       did it  \n",
       "4                         east-gemrman-dissent    outspoken  \n",
       "..                                         ...          ...  \n",
       "315                  essay-the-nsc-after-clark  experienced  \n",
       "316                  essay-the-nsc-after-clark    outspoken  \n",
       "317                 essay-the-recession-speaks     laid off  \n",
       "318              essay-the-ultimate-settlement   let him go  \n",
       "319                     presidential-paradoxes  experienced  \n",
       "\n",
       "[320 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('archive_euphemism_sentences.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df= pd.read_csv('train_euphemism_sentences.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "vectorizer.fit(euph_df['edited_text'])  # Fit on the entire training corpus\n",
    "\n",
    "X_train = vectorizer.transform(euph_df['edited_text'])\n",
    "y_train_category = euph_df['category']\n",
    "y_train_status = euph_df['euph_status']\n",
    "\n",
    "# Train a model for category\n",
    "model_category = LogisticRegression(random_state=42)\n",
    "model_category.fit(X_train, y_train_category)\n",
    "\n",
    "# Train a model for euph status\n",
    "model_status = LogisticRegression(random_state=42)\n",
    "model_status.fit(X_train, y_train_status)\n",
    "\n",
    "# Prepare results_df data for prediction\n",
    "X_results = vectorizer.transform(results_df['sentence'])\n",
    "\n",
    "# Predict categories and statuses\n",
    "results_df['predicted_category'] = model_category.predict(X_results)\n",
    "results_df['predicted_status'] = model_status.predict(X_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\yasmi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Assuming you have a DataFrame 'results_df' with a column 'sentence'\n",
    "def pos_tag_sentences(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    return nltk.pos_tag(tokens)\n",
    "\n",
    "results_df['pos_tags'] = results_df['sentence'].apply(pos_tag_sentences)\n",
    "\n",
    "# Expand the pos_tags into separate rows\n",
    "all_tags = []\n",
    "for index, row in results_df.iterrows():\n",
    "    for word, tag in row['pos_tags']:\n",
    "        all_tags.append({\n",
    "            'author': row['author'],\n",
    "            'sentence': row['sentence'],\n",
    "            'pet': row['pet'],  # Assuming 'pet' is the column for euphemisms\n",
    "            'word': word,\n",
    "            'pos_tag': tag\n",
    "        })\n",
    "\n",
    "tags_df = pd.DataFrame(all_tags)\n",
    "\n",
    "tags_df['is_euphemism'] = tags_df.apply(lambda x: x['word'].lower() == x['pet'].lower(), axis=1)\n",
    "euphemism_tags = tags_df[tags_df['is_euphemism']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_df = tags_df[tags_df['is_euphemism']]\n",
    "tags_df= tags_df.drop(columns=['is_euphemism','word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>sentence</th>\n",
       "      <th>pet</th>\n",
       "      <th>pos_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bs</td>\n",
       "      <td>if she winds up as her party's default nominee...</td>\n",
       "      <td>late</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>bs</td>\n",
       "      <td>\" some readers may be inclined to dismiss this...</td>\n",
       "      <td>troubled</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>bs</td>\n",
       "      <td>because of the delta variant's vigorous attack...</td>\n",
       "      <td>experienced</td>\n",
       "      <td>VBN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>bs</td>\n",
       "      <td>the florida governor did, in fact, do well in ...</td>\n",
       "      <td>elderly</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>bs</td>\n",
       "      <td>\" of these, nearly two-thirds come from econom...</td>\n",
       "      <td>disadvantaged</td>\n",
       "      <td>VBN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21791</th>\n",
       "      <td>zt</td>\n",
       "      <td>protocols should allow the elderly to interact...</td>\n",
       "      <td>elderly</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21822</th>\n",
       "      <td>zt</td>\n",
       "      <td>it is too late to fix everything for this elec...</td>\n",
       "      <td>late</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21839</th>\n",
       "      <td>zt</td>\n",
       "      <td>i never do, maybe because i discovered it so late</td>\n",
       "      <td>late</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21860</th>\n",
       "      <td>zt</td>\n",
       "      <td>i had expected some of what i encountered -- i...</td>\n",
       "      <td>expecting</td>\n",
       "      <td>VBG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21885</th>\n",
       "      <td>zt</td>\n",
       "      <td>youtube has recently come under fire for recom...</td>\n",
       "      <td>outspoken</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>496 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      author                                           sentence  \\\n",
       "14        bs  if she winds up as her party's default nominee...   \n",
       "38        bs  \" some readers may be inclined to dismiss this...   \n",
       "82        bs  because of the delta variant's vigorous attack...   \n",
       "128       bs  the florida governor did, in fact, do well in ...   \n",
       "186       bs  \" of these, nearly two-thirds come from econom...   \n",
       "...      ...                                                ...   \n",
       "21791     zt  protocols should allow the elderly to interact...   \n",
       "21822     zt  it is too late to fix everything for this elec...   \n",
       "21839     zt  i never do, maybe because i discovered it so late   \n",
       "21860     zt  i had expected some of what i encountered -- i...   \n",
       "21885     zt  youtube has recently come under fire for recom...   \n",
       "\n",
       "                 pet pos_tag  \n",
       "14              late      RB  \n",
       "38          troubled      JJ  \n",
       "82       experienced     VBN  \n",
       "128          elderly      JJ  \n",
       "186    disadvantaged     VBN  \n",
       "...              ...     ...  \n",
       "21791        elderly      JJ  \n",
       "21822           late      JJ  \n",
       "21839           late      RB  \n",
       "21860      expecting     VBG  \n",
       "21885      outspoken      JJ  \n",
       "\n",
       "[496 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sentence_transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m SentenceTransformer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstsb-roberta-base\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Generate embeddings\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sentence_transformers'"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('stsb-roberta-base')\n",
    "\n",
    "# Generate embeddings\n",
    "embeddings = model.encode(euph_df['edited_text'])\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Reduce dimensions to 2D for visualization\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "reduced_embeddings = tsne.fit_transform(embeddings)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have an array 'labels' that indicates whether each sentence is euphemistic (1) or not (0)\n",
    "labels = [1, 0]  # Corresponding to the example sentences above\n",
    "colors = ['red' if x else 'blue' for x in euph_df['is_euph']]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1], c=colors)\n",
    "plt.title('Semantic Space of Sentences')\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "for i, text in enumerate(euph_df['edited_text']):\n",
    "    plt.annotate(text, (reduced_embeddings[i, 0], reduced_embeddings[i, 1]))\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
